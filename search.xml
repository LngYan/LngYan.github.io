<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hello 博客</title>
    <url>/2023/01/10/Hello%20Blog/</url>
    <content><![CDATA[<p>我是初来的初学者，请多多指教！</p>
<p>这是我的第一篇博客。</p>
<p>记录下我的目标希望在回首看到这篇文章的时候我已经达成目标！</p>
<h3 id="高级数据分析师"><a class="markdownIt-Anchor" href="#高级数据分析师"></a> 高级数据分析师</h3>
<p>踏入数据分析的队伍是因为能对未来数据进行预测是一个很有意思的挑战。后来，我直接报了个班，花了半年时间系统学习了数据分析的基础理解了数据采集、数据清洗、数据分析、数据挖掘的方方面面，在对数据分析的深层次的了解后，认识到数据分析是展现价值，而数据的深层挖掘预测出的结果是通过相关的算法计算并且依靠机器学习不优化学习出来所以说算法及机器学习才是核心，数据是计算的基础。所以现阶段对于数据分析的目标是熟悉业务数据分析并且学习数据挖掘等各个计算基础等进一步提高自己的相关知识能力，在未来可以依靠自己的能力立足。</p>
<h3 id="做一个十万粉up主"><a class="markdownIt-Anchor" href="#做一个十万粉up主"></a> 做一个十万粉up主</h3>
<p>B站刚开始建站的时候我就注册了一个账号，一直用到现在，看着B站的起起落落，以前12dore团队不亦乐乎的MC整活在到纯黑、陆夫人、黑桐谷歌的各种游戏解说都是我小时候的乐趣，也是我想做UP主的一个起因，可我依旧没有规划好我该往那个方向（区）发展，感觉我什么都想做但是没都做不好，冷焱的出现就是最好的例子，所以我挺对不起冷焱的，想给他丰富的一生却法将精力全部投入，现在想做的事情和我的精力以及资金完全相反，我会一步一步的将这个目标敲定！</p>
<p>最后，就是对未来事业的遐想。对于最想进的大厂我还没有具体详细地去了解过，如果可以我希望自己可以成立一个小型企业，邀请一些志同道合地人来尽情地发挥自己的想象动用自己的能力。</p>
<p>最后最后，你要相信自己一定能行！</p>
]]></content>
      <categories>
        <category>blog</category>
        <category>target</category>
      </categories>
      <tags>
        <tag>初学者</tag>
        <tag>静态HTML</tag>
        <tag>blog</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo 搭建入门</title>
    <url>/2023/01/31/Hexo%20%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%89%80%E8%B5%B0%E8%BF%87%E7%9A%84%E5%9D%91/</url>
    <content><![CDATA[<h2 id="前沿"><a class="markdownIt-Anchor" href="#前沿"></a> 前沿</h2>
<h3 id="为何搭建博客"><a class="markdownIt-Anchor" href="#为何搭建博客"></a> 为何搭建博客</h3>
<p>建立博客的想法是在学习中一位老师推荐的，后来，随着个人知识面的拓展和深入，发现有太多的知识和经验值得沉淀和交流，在某年没有回家过春节的时候沉下心来搭建了一个博客，算是自己有一个回顾复盘的地方了吧。</p>
<p>另外，根据“学习金字塔”理论（Edgar Dale，1946），<strong>对知识进行演示、实践和传授能够显著提升学习保持率</strong>，而沉淀为博客或视频正是这样一种形式，我认为一方面可以让无形的知识转为有形的博客，便于之后复习和追溯，另一方面通过沉淀转化可以提高我对知识的记忆和掌握水平。</p>
<h3 id="建设原理"><a class="markdownIt-Anchor" href="#建设原理"></a> 建设原理</h3>
<p>博客自然是重内容，轻形式，主要重心点放在内容上，仅保留少量的交流功能即可。</p>
<p>这里我使用 <a href="https://hexo.io/">Hexo</a> 框架搭建博客，该框架基于 <a href="https://nodejs.org/zh-cn/">Node.js</a> ，使用者不需要掌握 node 原理，<a href="https://hexo.io/">Hexo</a> 会根据配置项中预设好的模板自动将内容转换为静态页面。</p>
<p>Hexo 提供了多种形式的主题：这里我选用的是 <a href="https://github.com/Fechin/hexo-theme-diaspora">Diaspora</a>。该主题较为贴近我对博客美观性的要求，且原生支持一系列配置项和插件，能满足我的需要。</p>
<p>虽然我有自己的NAS，但是为了提高其可用性，我还是白嫖了 GitHub Pages 服务，将 Hexo 生成的静态页面部署上去，从而可以让大家访问。</p>
<h2 id="基础环境安装"><a class="markdownIt-Anchor" href="#基础环境安装"></a> 基础环境安装</h2>
<h3 id="安装-nodejs"><a class="markdownIt-Anchor" href="#安装-nodejs"></a> 安装 Node.js</h3>
<p>直接到官网上下载安装即可https://nodejs.org/en/download/</p>
<ul>
<li>Node.js (Node.js 版本需不低于 10.13，建议使用 Node.js 12.0 及以上版本)</li>
<li>Node自带npm</li>
</ul>
<p>安装完成后在终端运行如下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ node -v</span><br><span class="line">$ npm  -v</span><br></pre></td></tr></table></figure>
<p>如果正常响应对应版本号，则说明安装及环境变量配置成功。</p>
<h3 id="安装git"><a class="markdownIt-Anchor" href="#安装git"></a> 安装Git</h3>
<p>安装Git需要用到安装器，我电脑上已安装HomeBrew所以可以直接安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">brew install git   // 安装Git</span><br></pre></td></tr></table></figure>
<p>也可以下载<a href="https://sourceforge.net/projects/git-osx-installer/">安装程序</a>来安装</p>
<h3 id="安装-hexo"><a class="markdownIt-Anchor" href="#安装-hexo"></a> 安装 Hexo</h3>
<p>使用 npm（node 的包管理器，可以类比 python 的 pip）可以直接安装 Hexo。在终端输入如下命令开始安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo npm install hexo-cli -g</span><br></pre></td></tr></table></figure>
<p>检查是否安装正常。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo -v</span><br></pre></td></tr></table></figure>
<p>安装后就可以开始配置了，选择一个本地文件夹作为博客的目录，终端切换到该目录下，初始化该目录并加载目录路径：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hexo init &lt;folder&gt;</span><br><span class="line">$ cd &lt;folder&gt;</span><br></pre></td></tr></table></figure>
<p>成功运行后，即可使用 hexo 的命令对该目录进行操作了</p>
<p><img src="/images/pasted-1.png" alt="upload successful" /><br />
运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>即可从本地运行博客服务器。浏览器打开终端提示的页面(默认为 <a href="https://localhost:4000">https://localhost:4000</a>)，即可查看。</p>
<p>默认页面为内置的 <a href="http://hello-world.md">hello-world.md</a> 文档。至此我们已经完成了 <a href="https://hexo.io/zh-cn/">Hexo</a>的安装，如要了解更多配置项可参考<a href="https://hexo.io/zh-cn/api/">Configuration | Hexo</a>，要了解更多 Hexo 命令可参考 <a href="https://hexo.io/zh-cn/api/">Commands | Hexo</a>。</p>
<h3 id="主题安装"><a class="markdownIt-Anchor" href="#主题安装"></a> 主题安装</h3>
<p>为了使博客不太难看，我们需要安装一个主题就拿我目前用的<a href="https://github.com/Fechin/hexo-theme-diaspora">Diaspora</a>主题来举例，进入安装Hexo目录，安装主题：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cd &lt;folder&gt;</span><br><span class="line">$ git clone https://github.com/Fechin/hexo-theme-diaspora.git themes/diaspora</span><br></pre></td></tr></table></figure>
<p>安装完成后在theme文件夹内会多出一个名为Diaspora(刚刚安装的主题）文件夹就说明安装成功了<br />
接下来启动和设置主题，修改Hexo配置文件 <code>_config.yml</code> 主题项设置为diaspora</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">theme: diaspora</span><br></pre></td></tr></table></figure>
<p>如何设置主题可以在<a href="https://github.com/Fechin/hexo-theme-diaspora">Diaspora</a>里查询</p>
<p>注意：请在更时主题时备份 <code>_config.yml</code>配置文件</p>
<p>配置好主题后重新启动hexo你的博客就更新为你设置的主题啦</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ hexo s</span><br></pre></td></tr></table></figure>
<p>当然Hexo还有非常多的主题供你选择。</p>
<h3 id="写文章"><a class="markdownIt-Anchor" href="#写文章"></a> 写文章</h3>
<p>所有基础框架都已经创建完成，接下来可以开始写你的第一篇博客了<br />
在<code>/source/_posts</code>下创建你的第一个博客吧，例如，创建一个名为<code>FirstNight.md</code>的文件，用Markdown大肆发挥吧，注意保存。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: First Night</span><br><span class="line">---</span><br><span class="line">&gt; 我有一头**小毛驴**，可是我从来都不骑。</span><br></pre></td></tr></table></figure>
<h2 id="发布"><a class="markdownIt-Anchor" href="#发布"></a> 发布</h2>
<p>测试没问题后，我们就生成静态网页文件发布至我们的Github pages 中或者自己的服务器上，国内的话可以发布到<a href="https://gitee.com/">gitee</a>上访问会快一些，毕竟git是国外网站，懂得都懂。<br />
<strong>在线发布</strong><br />
首先自己先注册个账号，注册过程可能需要验证你的邮箱，其他就不在赘述。</p>
<p>配置 Github 仓库：</p>
<p>需要创建一个仓库(repository) 来存储我们的网站，点击首页任意位置出现的 New repository按钮创建仓库, Respository name 中的<code>username.github.io</code>的username 一定与前面的Owner 一致，记住你的<code>username</code>下面会用到。</p>
<p><img src="/images/pasted-2.png" alt="upload successful" /></p>
<p>将 Hexo 文件夹中的文件 push 到储存库的默认分支，默认分支通常名为 main，旧一点的储存库可能名为 master。</p>
<ul>
<li>将 <strong>main</strong> 分支 push 到 GitHub：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git push -u origin main</span><br></pre></td></tr></table></figure>
<ul>
<li>默认情况下 public/ 不会被上传(也不该被上传)，确保 .gitignore 文件中包含一行 public/。整体文件夹结构应该与 范例储存库 大致相似。</li>
</ul>
<p>使用 node --version 指令检查你电脑上的 Node.js 版本，并记下该版本 (例如：<code>v16.y.z</code>)<br />
在储存库中建立 <code>.github/workflows/pages.yml</code>（特别注意路径我就踩过坑把文件存在了根目录下），并填入以下内容 (将 16 替换为上个步骤中记下的版本)：</p>
<pre class="highlight"><code class="yml"><span class="hljs-string">.github/workflows/pages.yml</span>

<span class="hljs-attr">name:</span> <span class="hljs-string">Pages</span>
<span class="hljs-attr">on:</span>
  <span class="hljs-attr">push:</span>
    <span class="hljs-attr">branches:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">main</span> <span class="hljs-comment"># default branch</span>
<span class="hljs-attr">jobs:</span>
  <span class="hljs-attr">pages:</span>
    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span>
    <span class="hljs-attr">steps:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v2</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Use</span> <span class="hljs-string">Node.js</span> <span class="hljs-number">16.</span><span class="hljs-string">x</span>
        <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/setup-node@v2</span>
        <span class="hljs-attr">with:</span>
          <span class="hljs-attr">node-version:</span> <span class="hljs-string">"16"</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Cache</span> <span class="hljs-string">NPM</span> <span class="hljs-string">dependencies</span>
        <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/cache@v2</span>
        <span class="hljs-attr">with:</span>
          <span class="hljs-attr">path:</span> <span class="hljs-string">node_modules</span>
          <span class="hljs-attr">key:</span> <span class="hljs-string">$&#123;&#123; runner.OS &#125;&#125;-npm-cache</span>
          <span class="hljs-attr">restore-keys:</span> <span class="hljs-string">|
            $&#123;&#123; runner.OS &#125;&#125;-npm-cache
</span>      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Install</span> <span class="hljs-string">Dependencies</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">npm</span> <span class="hljs-string">install</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Build</span>
        <span class="hljs-attr">run:</span> <span class="hljs-string">npm</span> <span class="hljs-string">run</span> <span class="hljs-string">build</span>
      <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Deploy</span>
        <span class="hljs-attr">uses:</span> <span class="hljs-string">peaceiris/actions-gh-pages@v3</span>
        <span class="hljs-attr">with:</span>
          <span class="hljs-attr">github_token:</span> <span class="hljs-string">$&#123;&#123; secrets.GITHUB_TOKEN &#125;&#125;</span>
          <span class="hljs-attr">publish_dir:</span> <span class="hljs-string">./public</span>
</code></pre>
<p>当部署作业完成后，产生的页面会放在储存库中的 gh-pages 分支。<br />
在储存库中前往 Settings &gt; Pages &gt; Source，并将 branch 改为 gh-pages。</p>
<p><img src="/images/pasted-3.png" alt="upload successful" /></p>
<p>过几分钟后，访问上方的网站，就可以看见你博客就搭建成功啦！</p>
<h2 id="更多"><a class="markdownIt-Anchor" href="#更多"></a> 更多</h2>
<p><a href="https://hexo.io/themes/">更多主题</a><br />
<a href="https://hexo.io/plugins/">更多插件</a></p>
]]></content>
      <categories>
        <category>Hexo</category>
        <category>blog</category>
      </categories>
      <tags>
        <tag>博客</tag>
        <tag>个人网站</tag>
      </tags>
  </entry>
  <entry>
    <title>K邻近（KNN）算法</title>
    <url>/2023/03/10/K%E9%82%BB%E8%BF%91%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h1 id="knn分类模型"><a class="markdownIt-Anchor" href="#knn分类模型"></a> KNN分类模型</h1>
<p>k 近邻（k-Nearest Neighbor，kNN）是机器学习中相对简单且容易理解的算法，是分类数据最简单有效的算法，它基于实例学习，我们必须用最真实的样本数据对模型进行训练，以便预测出的结果更具参考意义。<br />
<img src="/images/K%E9%82%BB%E8%BF%91%E7%AE%97%E6%B3%951.PNG" alt="img" /><br />
简单地说，k 近邻算法采用测量不同特征值之间的距离方法进行分类。这句话简单也不简单。更通俗易懂的理解，所谓“物以类聚，人以群分”，kNN 认为彼此相隔最近的点为一类。周围的对象是什么类别，我就是什么类别。如果你的朋友都开法拉利、保时捷等跑车，那么在 kNN 眼你，你也是有钱人，也开豪车。</p>
<h2 id="工作原理"><a class="markdownIt-Anchor" href="#工作原理"></a> 工作原理</h2>
<p>存在一个样本数据集合，也称作训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据 与所属分类的对应关系。输人没有标签的新数据后，将新数据的每个特征与样本集中数据对应的 特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们 只选择样本数据集中前K个最相似的数据，这就是K-近邻算法中K的出处,通常K是不大于20的整数。 最后 ，选择K个最相似数据中出现次数最多的分类，作为新数据的分类。</p>
<blockquote>
<ul>
<li>对未知类型的数据集中的每个点依次执行如下操作：
<ul>
<li>计算已知类别数据集中的点与当前点之间的距离；</li>
<li>按距离递增次序排序；</li>
<li>选取与当前点距离最小的 k 个点；</li>
<li>确认前 k 个点出现频率最高的类别作为当前点的预测分类；</li>
</ul>
</li>
</ul>
</blockquote>
<p>接下来，举个栗子带大家更好的理解 kNN 算法。如图，有黄色的管理人才，深蓝色的架构师，以及未知的天蓝色。</p>
<p><img src="/images/K%E9%82%BB%E8%BF%91%E7%AE%97%E6%B3%952.PNG" alt="img" /></p>
<p>当我们需要对员工进行技术和管理两个培养方向分类时，可能会考虑到他们的情商、沟通、技能、协作、远见、解决问题等能力。由于人类大脑的限制，我们只能处理三维以下的事务，这里只列举两个特征“情商”和“技能”评分，假设情商分高可作为管理人才来培养，技能分高作为架构师人才来培养。</p>
<p>我们拿到了七个样本数据，每一个样本带有情商和技能特征，以及对应的标签，他们分布在图中的数据如下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">技能</th>
<th style="text-align:center">情商</th>
<th style="text-align:center">培养方向</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">43</td>
<td style="text-align:center">92</td>
<td style="text-align:center">管理</td>
</tr>
<tr>
<td style="text-align:center">60</td>
<td style="text-align:center">88</td>
<td style="text-align:center">管理</td>
</tr>
<tr>
<td style="text-align:center">69</td>
<td style="text-align:center">80</td>
<td style="text-align:center">架构师</td>
</tr>
<tr>
<td style="text-align:center">66</td>
<td style="text-align:center">78</td>
<td style="text-align:center">管理</td>
</tr>
<tr>
<td style="text-align:center">88</td>
<td style="text-align:center">50</td>
<td style="text-align:center">架构师</td>
</tr>
<tr>
<td style="text-align:center">80</td>
<td style="text-align:center">91</td>
<td style="text-align:center">管理</td>
</tr>
<tr>
<td style="text-align:center">96</td>
<td style="text-align:center">35</td>
<td style="text-align:center">架构师</td>
</tr>
<tr>
<td style="text-align:center">68</td>
<td style="text-align:center">80</td>
<td style="text-align:center">？</td>
</tr>
</tbody>
</table>
<p>现在的需求是通过天蓝色的特征值预测他更适合的培养方向，按照 kNN 算法的实现步骤，计算出天蓝色特征与样本集的距离。计算二维平面上两点 a(x1,y1) 与 b(x2,y2) 间的欧氏距离</p>
<p><img src="/images/K%E9%82%BB%E8%BF%91%E7%AE%97%E6%B3%953.PNG" alt="img" /><br />
按距离升序排序之后结果如下：</p>
<table>
<thead>
<tr>
<th style="text-align:center">技能</th>
<th style="text-align:center">情商</th>
<th style="text-align:center">欧式距离↑</th>
<th style="text-align:center">培养方向</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">69</td>
<td style="text-align:center">80</td>
<td style="text-align:center">1.0</td>
<td style="text-align:center">架构师</td>
</tr>
<tr>
<td style="text-align:center">66</td>
<td style="text-align:center">78</td>
<td style="text-align:center">2.83</td>
<td style="text-align:center">管理</td>
</tr>
<tr>
<td style="text-align:center">60</td>
<td style="text-align:center">88</td>
<td style="text-align:center">11.31</td>
<td style="text-align:center">管理</td>
</tr>
<tr>
<td style="text-align:center">80</td>
<td style="text-align:center">91</td>
<td style="text-align:center">16.27</td>
<td style="text-align:center">管理</td>
</tr>
<tr>
<td style="text-align:center">43</td>
<td style="text-align:center">92</td>
<td style="text-align:center">27.73</td>
<td style="text-align:center">管理</td>
</tr>
<tr>
<td style="text-align:center">88</td>
<td style="text-align:center">50</td>
<td style="text-align:center">36.06</td>
<td style="text-align:center">架构师</td>
</tr>
<tr>
<td style="text-align:center">96</td>
<td style="text-align:center">35</td>
<td style="text-align:center">53.0</td>
<td style="text-align:center">架构师</td>
</tr>
</tbody>
</table>
<p>我们得到了预测数据与各个样本间的距离，并按递增排好序。现假设 k = 3，对应的类别分别是“架构师”、“管理”、“管理”，按照算法实现的第 4 步，前 3 个点出现频率最高的类别是“管理”。那么，天蓝色的培养方向应该偏管理。</p>
<p>实例中 k 值取多少没有定论，如果实例中 k = 1 或 k = 2，那么结果未必是最准确的，这是一个经验值。通常 k 是 3 ≤ k &lt; 20 的整数，并且是奇数，这样避免出现相同票数。</p>
<p>回过头来看数据分布图，以你为中心画圆，其中圆 c1 也就是 k = 1，距你最近的是“架构师”，圆 c2 则是当 k = 3 的时候，其中三个“管理”，少数服从多数，统计最多的类别依然是“管理”。</p>
<h2 id="knn优缺点"><a class="markdownIt-Anchor" href="#knn优缺点"></a> KNN优缺点</h2>
<p><strong>优点：精度高、对异常值不敏感、无数据输入假定。</strong><br />
缺点：kNN 必须保存全部数据集，会占用大量的存储空间，所以空间负责度高；<strong>kNN 必须对数据集中的每个数据计算距离值，实际使用时非常耗时，所以计算复杂度高。</strong></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#在scikit-learn库中使用k-近邻算法</span></span><br><span class="line">   <span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br></pre></td></tr></table></figure>
<h1 id="交叉验证"><a class="markdownIt-Anchor" href="#交叉验证"></a> 交叉验证</h1>
<ul>
<li>学习曲线&amp;交叉验证选取K值
<ul>
<li>K值较小，则模型复杂度较高，容易发生过拟合，学习的估计误差会增大，预测结果对近邻的实例点非常敏感。</li>
<li>K值较大可以减少学习的估计误差，但是学习的近似误差会增大，与输入实例较远的训练实例也会对预测起作用，使预测发生错误，k值增大模型的复杂度会下降。</li>
<li>在应用中，k值一般取一个比较小的值，通常采用交叉验证法来来选取最优的K值。</li>
</ul>
</li>
<li>适用场景
<ul>
<li>小数据场景，样本为几千，几万的</li>
</ul>
</li>
<li>目的：
<ul>
<li>选出最为适合的模型超参数的取值，然后将超参数的值作用到模型的创建中。</li>
</ul>
</li>
<li>思想：
<ul>
<li>将样本的训练数据交叉的拆分出不同的训练集和验证集，使用交叉拆分出不同的训练集和验证集测分别试模型的精准度，然就求出的精准度的均值就是此次交叉验证的结果。将交叉验证作用到不同的超参数中，选取出精准度最高的超参数作为模型创建的超参数即可！</li>
</ul>
</li>
<li>实现思路：
<ul>
<li>将训练数据平均分割成K个等份</li>
<li>使用1份数据作为验证数据，其余作为训练数据</li>
<li>计算验证准确率</li>
<li>使用不同的测试集，重复2、3步骤</li>
<li>对准确率做平均，作为对未知数据预测准确率的估计</li>
</ul>
</li>
</ul>
<p><img src="/images/K%E9%82%BB%E8%BF%91%E7%AE%97%E6%B3%954.PNG" alt="img" /></p>
<blockquote>
<ul>
<li>API
<ul>
<li>from sklearn.model_selection import cross_val_score</li>
<li>cross_val_score(estimator,X,y,cv):
<ul>
<li>estimator:模型对象</li>
<li>X,y:训练集数据</li>
<li>cv：折数</li>
</ul>
</li>
</ul>
</li>
</ul>
</blockquote>
]]></content>
      <categories>
        <category>数据分析</category>
        <category>数据挖掘</category>
        <category>机器学习</category>
        <category>KNN</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数据挖掘</tag>
        <tag>机器学习</tag>
        <tag>KNN</tag>
      </tags>
  </entry>
  <entry>
    <title>了解chatGPT</title>
    <url>/2023/02/12/%E4%BA%86%E8%A7%A3%E7%88%86%E7%81%AB%E7%9A%84chatGPT/</url>
    <content><![CDATA[<p>近期chatGPT刷爆的所有人的首页、社交平台、朋友圈，如此火爆的背后是人工智能发展出萌芽的第一步，所以我也去网上收集了许多资料，会在这里分享给大家。</p>
<p><img src="/images/chatGPT7.jpg" alt="img" /></p>
<h2 id="chatgpt是什么"><a class="markdownIt-Anchor" href="#chatgpt是什么"></a> 【ChatGPT是什么？】</h2>
<p>首先，ChatGPT 是由OpenAI公司在2022年11月30日发布的一种聊天机器人模型，是由人工智能技术驱动的自然语言处理工具，其中 Chat 就是聊天。当然不是像小爱同学、siri等智能家居系统这样简单的回答以及完型填空，chatGPT更像是回答你出的命题作文一样进行写作。</p>
<p>然后重点是后面的 <strong>【GPT】</strong> ，即 <strong>Generative Pre-trained Transformer</strong> ，中文叫 <strong>“生成型预训练变换模型”</strong>。<br />
简单来说，ChatGPT就像我们手机上的一款APP，不同之处在于，他能学习和理解人类的语言，还能根据上下文的语境进行反应，真正像人一样和你进行交流，同时他一门应用不是技术，并且chatGPT最重要的不是技术而是工程。</p>
<p>不仅仅只是聊天的chatGPT还能：</p>
<ul>
<li>[✓] 写代码、修bug</li>
<li>[✓] 设计装修图</li>
<li>[✓] 写剧本，写论文</li>
<li>[✓] 解析物理题<br />
如果你的提问当中出现明显的错误，他还会纠正你。</li>
</ul>
<h2 id="chatgpt的由来"><a class="markdownIt-Anchor" href="#chatgpt的由来"></a> 【chatGPT的由来】</h2>
<p>2017年，谷歌大脑团队（Google Brain）在神经信息处理系统大会（NeurIPS，该会议为机器学习与人工智能领域的顶级学术会议）发表了一篇名为“Attention is all you need”（自我注意力是你所需要的全部）的论文。作者在文中首次提出了基于自我注意力机制（self-attention）的变换器（transformer）模型，并首次将其用于理解人类的语言，即自然语言处理。</p>
<p>在这篇文章面世之前，自然语言处理领域的主流模型是循环神经网络（RNN，recurrent neural network）。循环神经网络模型的优点是，能更好地处理有先后顺序的数据，比如语言，但也因为如此，这种模型在处理较长序列，例如长文章、书籍时，存在模型不稳定或者模型过早停止有效训练的问题（这是由于模型训练时的梯度消失或梯度爆炸现象而导致，在此不具体展开），以及训练模型时间过长（因必须顺序处理数据，无法同时并行训练）的问题。</p>
<p>2015年12月，OpenAI公司美国旧金山成立。特斯拉的创始人马斯克也是该公司创始人之一，为公司早期提供了资金支持（后来他从该公司退出，但保留了金主身份，并未撤资）。成立早期，OpenAI是一家非营利组织，以研发对人类社会有益、友好的人工智能技术为使命。2019年，OpenAI改变了其性质，宣布成为营利机构，这个改变与Transformer模型不无相关。</p>
<p>2018年，在Transformer模型诞生还不到一年的时候，OpenAI公司发表了论文“Improving Language Understanding by Generative Pre-training”（用创造型预训练提高模型的语言理解力）（Generative一般译为“生成型”，但我认为译为“创造型”更合适），推出了具有1.17亿个参数的GPT-1（Generative Pre-training Transformers, 创造型预训练变换器）模型。这是一个用大量数据训练好的基于Transformer结构的模型。他们使用了经典的大型书籍文本数据集（BookCorpus）进行模型预训练。该数据集包含超过7000本从未出版的书，类型涵盖了冒险、奇幻、言情等类别。在预训练之后，作者针对四种不同的语言场景、使用不同的特定数据集对模型进行进一步的训练（又称为微调，fine-tuning）。最终训练所得的模型在问答、文本相似性评估、语义蕴含判定、以及文本分类这四种语言场景，都取得了比基础Transformer模型更优的结果，成为了新的业内第一。<br />
<img src="/images/chatGPT1.jpg" alt="img" /></p>
<p>2019年，该公司公布了一个具有15亿个参数的模型：GPT-2。该模型架构与GPT-1原理相同，主要区别是GPT-2的规模更大（10倍）。同时，他们发表了介绍这个模型的论文“Language Models are Unsupervised Multitask Learners” （语言模型是无监督的多任务学习者）。在这项工作中，他们使用了自己收集的以网页文字信息为主的新的数据集。不出意料，GPT-2模型刷新了大型语言模型在多项语言场景的评分记录。在文中，他们提供了GPT-2模型回答新问题（模型训练数据中未出现过的问题及其答案）的结果。</p>
<p>2020年，这个创业团队再次战胜自己，发表论文“Language Models are Few-ShotLearner”（语言模型是小样本学习者），并推出了最新的GPT-3模型——它有1750亿个参数。GPT-3模型架构与GPT-2没有本质区别，除了规模大了整整两个数量级以外。GPT-3的训练集也比前两款GPT模型要大得多：经过基础过滤的全网页爬虫数据集（4290亿个词符）、维基百科文章（30亿词符）、两个不同的书籍数据集（一共670亿词符）。</p>
<p>由于巨大的参数数目以及训练所需数据集规模，训练一个GPT-3模型保守估计需要五百万美元至两千万美元不等——如果用于训练的GPU越多，成本越高，时间越短；反之亦然。可以说，这个数量级的大型语言模型已经不是普通学者、一般个人能负担得起研究项目了。面对如此庞大的GPT-3模型，用户可以仅提供小样本的提示语、或者完全不提供提示而直接询问，就能获得符合要求的高质量答案。小样本提示是指用户在提问时先给模型提供几个例子，然后再提出自己的语言任务（翻译、创作文本、回答问题等）。</p>
<p><img src="/images/chatGPT2.jpg" alt="img" /></p>
<p>GPT-3模型面世时，未提供广泛的用户交互界面，并且要求用户提交申请、申请批准后才能注册，所以直接体验过GPT-3模型的人数并不多。根据体验过的人们在网上分享的体验，我们可以知道GPT-3可以根据简单的提示自动生成完整的、文从字顺的长文章，让人几乎不能相信这是机器的作品。GPT-3还会写程序代码、创作菜谱等几乎所有的文本创作类的任务。早期测试结束后，OpenAI公司对GPT-3模型进行了商业化：付费用户可以通过应用程序接口（API）连上GPT-3，使用该模型完成所需语言任务。2020年9月，微软公司获得了GPT-3模型的独占许可，意味着微软公司可以独家接触到GPT-3的源代码。该独占许可不影响付费用户通过API继续使用GPT-3模型。</p>
<p>2022年3月，OpenAI再次发表论文“Training language models to follow instructions with human feedback”（结合人类反馈信息来训练语言模型使其能理解指令），并推出了他们基于GPT-3模型并进行了进一步的微调的InstructGPT模型。InstructGPT的模型训练中加入了人类的评价和反馈数据，而不仅仅是事先准备好的数据集。</p>
<p>GPT-3公测期间用户提供了大量的对话和提示语数据，而OpenAI公司内部的数据标记团队也生成了不少人工标记数据集。这些标注过的数据（labelled data），可以帮助模型在直接学习数据的同时学习人类对这些数据的标记（例如某些句子、词组是不好的，应尽量少使用）。</p>
<p>OpenAI公司第一步先用这些数据对GPT-3用监督式训练（supervised learning）进行了微调。</p>
<p>第二步，他们收集了微调过的模型生成的答案样本。一般来说，对于每一条提示语，模型可以给出无数个答案，而用户一般只想看到一个答案（这也是符合人类交流的习惯），模型需要对这些答案排序，选出最优。所以，数据标记团队在这一步对所有可能的答案进行人工打分排序，选出最符合人类思考交流习惯的答案。这些人工打分的结果可以进一步建立奖励模型——奖励模型可以自动给语言模型奖励反馈，达到鼓励语言模型给出好的答案、抑制不好的答案的目的，帮助模型自动寻出最优答案。</p>
<p>第三步，该团队使用奖励模型和更多的标注过的数据继续优化微调过的语言模型，并且进行迭代。最终得到的模型被称为InstructGPT。</p>
<p><img src="/images/chatGPT4.jpg" alt="img" /><br />
<img src="/images/chatGPT3.jpg" alt="img" /></p>
<h2 id="chatgpt的商业价值"><a class="markdownIt-Anchor" href="#chatgpt的商业价值"></a> 【ChatGPT的商业价值】</h2>
<p>在Open AI公司推出chatGPT程序之后，国内外的科技巨头都坐不住了：</p>
<ul>
<li>谷歌：自己也将推出同类型的AI聊天机器人；</li>
<li>苹果：马上通过彭博社宣布，将在近期举行AI峰会；</li>
<li>百度：正式官宣了公司类chatGPT项目“文心一言”，可以说是国内在人工智能领域技术积淀最深的企业；</li>
<li>阿里巴巴：阿里达摩院研发的类似对话机器人，已经在开放给内部员工进行内测的阶段；<br />
…</li>
</ul>
<p>说到底，ChatGPT本身是一个现象，现象背后的人工智能趋势，才是真正最重要的。</p>
<p>科技巨头们急了，是因为他们深怕错过了这一波人工智能浪潮的红利。</p>
<p>OpenAI推出ChatGPT付费订阅版ChatGPTPlus，每月收费20美元，开启产品走向商业化变现道路。</p>
<p>随着智能客服、教育、医疗、搜索引擎等应用领域不断落地，ChatGPT将与各行业应用结合后，更多付费商业模式即将落地AI人工智能的赛道将变的越来越壮大。</p>
<p>这里不得不提到AIGC，即人工智能生成内容，ChatGPT、AI 绘画、AI数字虚拟人、AI智能客服等都是AIGC的范畴，将是未来人工智能的重要发展方向。<br />
<img src="/images/chatGPT8.jpg" alt="img" /></p>
<h2 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h2>
<p>ChatGPT能够促使AIGC快速商业化发展，预示着自然语言处理（NLP）技术有望迅速进入平民化应用时代，应用场景不断拓宽…</p>
<p>所以ChatGPT的一小步，是AI的一大步!</p>
<p>ChatGPT也引发了很多人的焦虑和失业危机：</p>
<blockquote>
<p>① 简单的数据处理和录入工作者；<br />
② 简单的客服工作者；<br />
③ 简单的金融分析和记账工作者；<br />
④ 重复性高的生产线工作；</p>
</blockquote>
<p>当然，有些岗位可能会因此得到提升，例如:</p>
<blockquote>
<p>① 人工智能开发人员;<br />
② 数据分析师;<br />
③ 自动化工程师;<br />
④ 用户体验设计师等。</p>
</blockquote>
<p>以及在2023年2月出台的规范使用，媒体报道称，欧盟负责内部市场的委员蒂埃里·布雷东日前就“聊天生成预训练转换器”发表评论说，这类人工智能技术可能为商业和民生带来巨大的机遇，但同时也伴随着风险，因此欧盟正在考虑设立规章制度，以规范其使用，确保向用户提供高质量、有价值的信息和数据。</p>
<p>随着法律规范，商业应用的陆续提上日程等一系列信息，都表明AI的发展将进入到加速阶段，那么AI究竟是何发展？让我们拭目以待吧！</p>
<p><strong>最后呢还是要强调下，ChatGPT本身是一个现象，现象背后的人工智能趋势，才是真正最重要的。</strong></p>
<h2 id="更多"><a class="markdownIt-Anchor" href="#更多"></a> 更多</h2>
<blockquote>
<p>人工智能的两条基础理念：<br />
1、有内在规律，有概率的、不能百分百保证预测正确。<br />
2、可采集数据，可以做随机数据获取大量机器学习的基础。</p>
</blockquote>
<blockquote>
<p>人工智能的两个过程：<br />
1、训练：从老数据中挖掘数据的规律。<br />
2、预测：讲挖掘到的规律运用到新数据中。</p>
</blockquote>
<blockquote>
<p>人工智能优势与劣势：<br />
1、强项：规则比较模糊的场景<br />
2、弱项：规则比较清晰的场景</p>
</blockquote>
<blockquote>
<p>初入人工智能项目流程：<br />
1、确认好输入输出<br />
2、根据输入输出，采集数据<br />
3、遴选算法，完成训练<br />
4、模型部署，上线推理</p>
</blockquote>
<p>加减乘除不适合人工智能来做，计算器来算才是百分百正确。</p>
<p><strong>人工智能就是拥有“人”的特点。</strong></p>
<p><img src="/images/chatGPT5.jpg" alt="img" /><br />
<img src="/images/chatGPT6.jpg" alt="img" /></p>
]]></content>
      <categories>
        <category>人工智能</category>
        <category>chatGPT</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>chatGPT</tag>
      </tags>
  </entry>
  <entry>
    <title>如何注册chatGPT</title>
    <url>/2023/02/13/%E5%A6%82%E4%BD%95%E6%B3%A8%E5%86%8CchatGPT/</url>
    <content><![CDATA[<h2 id="注册"><a class="markdownIt-Anchor" href="#注册"></a> 注册</h2>
<p>1、魔法上网，可以使用国外的节点，<strong>但不能是香港、澳门、台湾等的节点</strong>。日本、美国、新加坡等区域亲测可以（看网络上不少网友反馈港澳台和部分地区会被openAI封锁，注册前请确认自己的环境）。<br />
2、国外的手机号码，同样地区也是如上述网络环境之外的地区手机号（注意部分虚拟手机号的厂家无法接受验证码，请注意甄别）。</p>
<h2 id="流程"><a class="markdownIt-Anchor" href="#流程"></a> 流程</h2>
<p>1.打开ChatGPT的官方网站，链接为https://chat.openai.com，然后点击【Sign Up】进入下一步。<br />
如果页面无法正常显示，需要更换其他的网络节点，或者清理下浏览器cookie再次尝试。<br />
<img src="/images/%E6%B3%A8%E5%86%8CchatGPT1.png" alt="img" /><br />
2.注册方式为邮箱注册，可以用微软帐号或者谷歌帐号登录，微软账号或者谷歌账号好像不需要验证，国内或者其他邮箱地址都需要进行验证（比如QQ邮箱是需要验证的）。<br />
<img src="/images/%E6%B3%A8%E5%86%8CchatGPT2.png" alt="img" /><br />
3.邮箱通过后，会提示你输入姓名，按照要求进行输入即可。如果显示该IP地址注册数量过多，则需要更换节点（更换节点时，无需对浏览器进行重启，刷新页面即可）。<br />
<img src="/images/%E6%B3%A8%E5%86%8CchatGPT3.png" alt="img" />）<br />
3.随后将会进入手机验证的环节，记住：这里不能选择国内的手机号，国内的手机号无法进行注册。<br />
<img src="/images/%E6%B3%A8%E5%86%8CchatGPT4.png" alt="img" /><br />
这里比较推荐俄罗斯的<a href="https://sms-activate.org">sms-activate</a>虚拟服务平台实时帮你接收验证码，非常快速而且里面不仅能接收open AI，其他平台也都能注册，强推！！！<br />
<img src="/images/%E6%B3%A8%E5%86%8CchatGPT6.png" alt="img" /><br />
注意，在接收验证码时，建议使用低价的印尼等手机号，印度经常挤爆收不到；如果长时间没有收到验证码，可更换成其他区域尝试。<br />
重点是：在手机验证页面，一定要注意选择正确的国家（注意国旗）！一定要注意选择正确的国家！一定要注意选择正确的国家！<br />
4.注册完毕后，就可以自由自在的使用ChatGPT了。<br />
<img src="/images/%E6%B3%A8%E5%86%8CchatGPT5.png" alt="img" /></p>
]]></content>
      <categories>
        <category>人工智能</category>
        <category>chatGPT</category>
      </categories>
      <tags>
        <tag>人工智能</tag>
        <tag>chatGPT</tag>
      </tags>
  </entry>
  <entry>
    <title>描述统计及推断统计</title>
    <url>/2023/02/07/%E6%8F%8F%E8%BF%B0%E7%BB%9F%E8%AE%A1%E5%8F%8A%E6%8E%A8%E6%96%AD%E7%BB%9F%E8%AE%A1/</url>
    <content><![CDATA[<h1 id="什么是统计学"><a class="markdownIt-Anchor" href="#什么是统计学"></a> 什么是统计学</h1>
<p>首先统计学是数据分析师必走的一条道路，它可以从科学的角度上说明数的收集、处理、分析和解释，并从数据中得出结论。当然最先遇到的难题就是映入眼前的一大堆让人懵逼的复杂数学公式，直接让人还没开始就直接开摆，但实际学习下来过后发现统计学就在我们身边也没有那么的难，也不一定要会很多公式的推导，我们首先是先理解，从应用层面上，然后再慢慢深入研究，知道他并且会用是我们的第一步，我们先将个最通俗易懂的例子：</p>
<blockquote>
<p>案例1：假设一家公司的老板说自己公司平均工资在20000左右，你是不是很心动？但实际上可能老板 60000 张三 6000 李四<br />
8000 王五 5000 所以你去过可能也就是5000～7000的水平可见这个坑有多深。<br />
案例二：2019年国家统计局发布的工资数据中提到：信息传输、软件和信息技术服务业平均工资得以快速增⻓，2019年平均工资为122478元，比上年增⻓9.3%</p>
</blockquote>
<p><img src="/images/%E6%8F%8F%E8%BF%B0%E7%BB%9F%E8%AE%A1%E5%8F%8A%E6%8E%A8%E6%96%AD%E7%BB%9F%E8%AE%A11.jpg" alt="img" /></p>
<p>这么看是不是发现统计学他时时刻刻都在我们身边？将他啃下，我们也能当一名会做生意的老板。<br />
大概讲明白了统计学的的例子，我们继续把统计学中两个重要的分支：描述统计和推断统计，在拿出来说说。</p>
<h2 id="描述统计"><a class="markdownIt-Anchor" href="#描述统计"></a> 描述统计</h2>
<ul>
<li>将一系列复杂数据，减少为几个能起到描述作用的数字（均值，中位数等），用这些有代表性的数字来代表整个数字集。然后还可以将代表性数据图形化/可视化，可以更直观的了解数据，从而用数据解释问题。</li>
<li>例如：说一下班级这次考试的情况如何</li>
</ul>
<p>那描述统计中又有：</p>
<ul>
<li>集中描述统计</li>
<li>离散趋势统计</li>
</ul>
<p>下面先讲解下集中描述统计和离散趋势统计</p>
<h3 id="集中描述统计"><a class="markdownIt-Anchor" href="#集中描述统计"></a> 集中描述统计</h3>
<p><strong>反映数据向其中心值靠拢或聚集的程度</strong></p>
<h4 id="均数"><a class="markdownIt-Anchor" href="#均数"></a> 均数</h4>
<p>描述一组数据在数量上的平均水平，主要用于数值型数据</p>
<ul>
<li>均数的优点：
<ul>
<li>高度浓缩了数据的精华，使大量的观测数据转变成一个代表性的数值；比较敏感，数据任何一个值发生变化，均数都会随之改变。</li>
<li>大家熟知、都比较喜欢用、便于比较和传播。</li>
</ul>
</li>
<li>均数的缺点：
<ul>
<li>大锅饭，把各个观测数据之间的差异性掩盖了</li>
<li>均数受极值的影响很大。</li>
<li>上文提到的平均工资的事情，就是均值的缺点造成的</li>
</ul>
</li>
<li>均数的使用范围
<ul>
<li>对称分布，特别是正态分布的数据比较适用，但是对于极端性数据均数绝对不适用</li>
</ul>
</li>
<li>pandas计算均值：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df.mean(axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h4 id="中位数"><a class="markdownIt-Anchor" href="#中位数"></a> 中位数</h4>
<p>主要用于顺序型数据。将全体数据从小到大排列，在整个数列中处于中间位置的那个值就是中位数。个数为奇数的中位数，根据位置取中间的那个数即可。个数为偶数的中位数，就是中间两个数值的均值。</p>
<ul>
<li>中位数的优点
<ul>
<li>不受极端值的影响，在具有个别极大或极小值的分布数列中，中位数比均数更具有代表性，如上面例子，用中位数则是4500，至少代表了前三个人的工资水平</li>
</ul>
</li>
<li>中位数的缺点
<ul>
<li>损失信息，只考虑居中位置，其他变量值比中位数大多少或小多少，它无法反映出来，所以我们也是只能看到部分信息。</li>
</ul>
</li>
<li>中位数的应用场景：
<ul>
<li>对于对称性的数据，优先均数，仅仅对于均数不能使用的情况才使用中位数加以描述。</li>
<li>在描述数据的时候，我们通常会通过平均数与中位数来认识数据。但有些时候，哪怕我们准确无误的计算出了平均数，也无法改变中位数在对真相的描述中更加准备这个事实，为什么这么说呢？
<ul>
<li>首先，我们关心的多大数现象都可以用多种方式进行描述。但同样的，当我们在对同一事物进行描述的时候，我们说的话（选用的数据）便会影响别人对此事的印象。</li>
<li>比如3、4、5、6、102这5个数字，它们的平均数是24，而中位数是5。很明显，24和5之间存在明显的差距。有些时候，你想让整体的数字看起来更大，就用平均数。如果你想让整体数字看起来更小，那就用中位数。这时，就很容易误导看数据的人。因为一看到你的平均数这么大，很自然的就会认为你的东⻄不错。其实不是的。因为这组数据的平均数之所以这么大，完全是因为102这个极值拉大了整体的均值，所以平均数看起来还错。只是这样的话，便会对数据产生一定的误解。因此，从这个⻆度出发，当我们要准确的认识数据的时候，要尽可能避免使用平均数来作为判断对象好坏的唯一标准，我们得加入中位数数据，使得结论更加准确。</li>
</ul>
</li>
</ul>
</li>
<li>pandas计算中位数/四分位数：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">df = DataFrame(data=np.random.randint(<span class="number">0</span>,<span class="number">100</span>,size=(<span class="number">3</span>,<span class="number">5</span>)))</span><br><span class="line">df.median(axis=<span class="number">1</span>) <span class="comment">#计算df中每一行的中位数，如果行数据不是有序的，</span></span><br><span class="line">则median会将其变为有序在计算中位数</span><br><span class="line">df.describe() <span class="comment">#可以将df的每一列进行统计描述</span></span><br></pre></td></tr></table></figure>
<h4 id="众数"><a class="markdownIt-Anchor" href="#众数"></a> 众数</h4>
<ul>
<li>众数是指总体中出现次数最多的标志值，简单来说就是一组数据当中，出现次数最多的那个数。在实际工作中，众数有相当广泛的应用。
<ul>
<li>例如，市场上某种商品一天的价格可能有多次变化，可不必全面登记该商品的全部价格来计算其算术平均数，而只需用该商品成交量最多的那个价格即众数作为代表值，就可以反映出该商品价格的一般水平。</li>
<li>又如，在大批量生产的男式皮鞋中有多种尺码，其中40码的销售量最多，这说明40码就是众数，可代表男式皮鞋尺码的一般水平，宜大量生产，而其余尺码的生产量就要相应少一些，这样才能满足市场上大部分消费者的需要。</li>
</ul>
</li>
<li>pandas计算众数：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = Series([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">s.mode() <span class="comment">#众数</span></span><br></pre></td></tr></table></figure>
<h3 id="离散趋势描述"><a class="markdownIt-Anchor" href="#离散趋势描述"></a> 离散趋势描述</h3>
<h4 id="方差"><a class="markdownIt-Anchor" href="#方差"></a> 方差</h4>
<ul>
<li>案例分析：
<ul>
<li>要从甲乙两名跳远运动员中选出一名去参加运动会，为此专⻔为两人进行了10次跳远比赛，产出了两个人各自10组跳远的成绩记录。选拔标准是，先看他们的平时成绩，如果平时成绩相差无几的话，在看稳定程度。那么，就可以使用方差来衡量其稳定程度。下面来看下，如何一步一步的推导出方差。</li>
</ul>
</li>
<li>提问：如果用一组数据的平均数来代表样本平均水平的话，对个体(每个数据)而言，什么指标可以代表个体(每个数据)的离散程度大小？（一次跳远成绩距离均值的距离）
<ul>
<li>可以使用离均差：x-μ（个体偏离均值的程度）</li>
</ul>
</li>
<li>提问：可否用离均差的总和来表示整个样本的离散程度？不可以，离均差有正负之分，加和会抵消为0。那怎么办，怎么解决正负号的问题？可以<strong>使用离均差的平方和：∑(x-μ)²</strong><br />
但是：<br />
如果比较两个样本的离均差，一个样本量是10个，一个是1000个，实际上二者的离散程度是一样的，但是因为数量不同，造成平方和相加和数值差异很大，这该怎么办？</li>
<li>显然，我们发现离均差平方和的大小跟样本量有关</li>
<li>如果我们能够把离均差平方和/样本量，是不是就解决了这个问题，其实这个就是方差的概念<br />
方差：反映各数据远离其中心值的趋势<br />
pandas计算方差：</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = Series([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">s.var()</span><br></pre></td></tr></table></figure>
<p>标准差<br />
方差开根号就是标准差</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">s = Series([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">s.std()</span><br></pre></td></tr></table></figure>
<p>思考：<br />
一组数据携带的信息量的大小可以使用方差来衡量方差越大表示这组数据携带的信息量越大，反之越小。</p>
<ul>
<li>第一组数据：9, 9.1, 9.01, 8.99， 9.1 方差几乎为0</li>
<li>第二组数据：9 102 22 1 0.8 方差较大</li>
</ul>
<h2 id="推断统计"><a class="markdownIt-Anchor" href="#推断统计"></a> 推断统计</h2>
<p>是研究如何利用样本数据来推断总体特征的统计方法。推断统计其实是建立在描述统计的基础之上，在对总体数据有了大致的了解之后，运用一些分析方法，对数据进行预测，并达到统计决策的目的，其实不管是在统计学上，还是在实际的业务分析中，我们做分析的终极目的就是用来得出我们结论，应用于决策。</p>
<ul>
<li>例如：房价预测，通过预测数据来进行销售，用户看到房价走势，如果一路走高，是不是要提早下手。</li>
</ul>
<p><img src="/images/%E6%8F%8F%E8%BF%B0%E7%BB%9F%E8%AE%A1%E5%8F%8A%E6%8E%A8%E6%96%AD%E7%BB%9F%E8%AE%A12.jpg" alt="img" /></p>
<hr />
<p>看完这个篇文章的内容后是否开始一点点的了解？如果还是没有了解也没关系，我们更多的是要了解如何应用进pandas当中，学习他们在分析中的作用，来帮助我们更好的完成所需要的工作。</p>
<p>之后我会找时间讲述下统计学中的几个概念，二项分布和正太分布，拜~</p>
]]></content>
      <categories>
        <category>数据分析</category>
        <category>统计学</category>
      </categories>
      <tags>
        <tag>统计学</tag>
        <tag>基础</tag>
        <tag>描述统计</tag>
        <tag>推断统计</tag>
      </tags>
  </entry>
  <entry>
    <title>数据分析之Excel</title>
    <url>/2023/02/05/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BExcel/</url>
    <content><![CDATA[<p>在一个数据驱动运营、数据决定对策、数据改变未来的时代。无论是海量数据库，还是一张简单的表格，都能进一步挖掘数据价值、活用数据。在众多数据分析工具中，Excel 是最常用，也是最容易上手的分析工具。<br />
<img src="/images/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BExcel1.jpg" alt="img" /><br />
Excel 数据分析功能十分强大，不仅提供简单的数据处理功能，还有专业的数据分析工具库，包括相关系数分析、描述统计分析等。</p>
<h2 id="为什么选择用excel"><a class="markdownIt-Anchor" href="#为什么选择用excel"></a> 为什么选择用Excel？</h2>
<p>1.Excel是非常常见普遍存在的工具不仅能完成日常常见的大部分内容，同时也是便捷的数据分析工具。功能非常强大有数据统计、函数计算、数据透视表、图表等功能。可以满足一般的数据分析需求。<br />
2.Excel简单易学。对于初学者来说，Excel从入门到精通，只要你每天花点时间学习及练习，一个月就可以掌握。<br />
3.做为office三剑客之一，Excel、Word、PPT的江湖地位是无可撼动的。 当然还有更多更专业的数据分析软件如Spss、Python等，也可以实现数据分析。 另外越来越多的公司建立了BI报表体系，用来做数据分析和展示，当然这个是需要一定的资金支持。</p>
<p>是的，就是你看不起的Excel，它能完成的大部分的事情包含但不限于：</p>
<blockquote>
<ul>
<li>数据清洗（完整、合法、唯一）</li>
<li>描述性统计分析（数据表现一秒生成）</li>
<li>变化和趋势分析（多维度分析、交叉分析）</li>
<li>回归和预测（数据之间内在关系有多可信）</li>
</ul>
</blockquote>
<h2 id="excel做数据分析方法"><a class="markdownIt-Anchor" href="#excel做数据分析方法"></a> Excel做数据分析方法</h2>
<p><img src="/images/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BExcel3.jpg" alt="img" /></p>
<h3 id="准备数据并生成透视表"><a class="markdownIt-Anchor" href="#准备数据并生成透视表"></a> 准备数据并生成透视表</h3>
<p>在excel数据中，将清洗完成的数据选中→插入→数据透视表，把地区、省份（需要汇总的维度）放到行，利润、销售额（需要汇总的数值）放到值。</p>
<h3 id="设计格式"><a class="markdownIt-Anchor" href="#设计格式"></a> 设计格式</h3>
<p>选中excel顶部菜单的设计→报表布局→已表格形式显示→分类汇总→不显示分类汇总，调整数据的展现格式</p>
<h3 id="插入切片器"><a class="markdownIt-Anchor" href="#插入切片器"></a> 插入切片器</h3>
<p>在excel顶部菜单中，找到分析→插入切片器→季度→确定。<br />
以上，数据透视表能帮我们统计数据源，切片器能帮助形成交互式报表，再通过公式提取数据生成图表。当使用切片器时，便生成了交互式图表。至此，excel做数据分析图的数据部分便做好了。</p>
<h3 id="条形图"><a class="markdownIt-Anchor" href="#条形图"></a> 条形图</h3>
<p>引用数据，用Large函数和Index+Match组合查找函数，在利润中提取排名前五和倒五的值和对应的省份，生成条形图。再选中数据→插入→查看所有图表→所有图表→条形图→簇状条形图，插入条形图。<br />
<img src="/images/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BExcel4.jpg" alt="img" /></p>
<h3 id="瀑布图"><a class="markdownIt-Anchor" href="#瀑布图"></a> 瀑布图</h3>
<p>引用数据，用Sumif函数对各地区的利润求和，选中数据→插入→查看所有图表→所有图表→瀑布图→确定→双击总计的柱子→鼠标右键→设置为汇总，生成瀑布图。瀑布图适用于展示数据之间的演变过程，能直观看出销售额从0变化到总计的一个过程。<br />
<img src="/images/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BExcel5.jpg" alt="img" /></p>
<h3 id="树状图"><a class="markdownIt-Anchor" href="#树状图"></a> 树状图</h3>
<p>用Vlookup函数查找利润，选中数据→插入→查看所有图表→所有图表→树状图→确定，生成树状图。树状图能快速了解比重情况及各区域分布详情。7、制作图表——折线图引用数据，用Sumif函数对各月的销售额求和，用Average函数求年销售额平均值。选中数据→插入→查看所有图表→所有图表→折线图→确定，生成折线图。折线图能分析每月销售额的变化情况，通过添加平均线，能帮助分析为什么这个月销售额高，为什么那个月销售额低。</p>
<h2 id="数据分析的几点硬核经验"><a class="markdownIt-Anchor" href="#数据分析的几点硬核经验"></a> 数据分析的几点硬核经验</h2>
<ol>
<li>务必提升数据采集的效率</li>
</ol>
<p>excel重处理而弱采集，尤其在大体量的公司，跨部门收集、汇总四面八方的数据，很崩溃特别是经常需要大面积采集数据，所以数据收集经常能将自己弄奔溃。</p>
<p>所以找了一些方便我们处理的表单工具（简道云、麦客、金数据、氚云等），一圈试下来，觉得钉钉+简道云可以搭配使用，数据收集效率还是很可观地。</p>
<p>数据采集还涉及线上数据爬取，但这方面我了解不多，就不班门弄斧了。有意者可以参考这篇回答：<br />
<a href="https://www.zhihu.com/question/20899988/answer/24923424">如何入门 Python 爬虫？</a><br />
<img src="/images/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BExcel6.jpg" alt="img" /><br />
2. 业务知识大于工具选择</p>
<p>所有数据分析师都会告诉后来人“业务知识很重要”，因为大家在踩了坑之后才恍然大悟分析中遇到的很多难题问题都源于对业务的不了解。</p>
<p>例如，同样是对客户进行分析，互联网电商的客户与保险客户具有明显区别，前者重视来源，活跃度，购买率，流失率，后者关注渠道，报价，理赔风险，投诉。业务知识包括这种大方向的行业知识，也包括公司内部特殊情况，了解得越详细可以避免绕很多弯路。</p>
<p>例如，有些行为是内部人员参与造成的数据异常要提前做处理，有些业务开展是带地区特性的，分析时候要区分对待等。</p>
<p>而真正做分析时候，你会发现市面上有太多的分析工具，需要掌握的实在是太多了，其实不必纠结于此，依据个人能力，配合当前的数据分析环境，适用的工具自然会被选出。</p>
<p>数据分析过来人都会说80％的时间都在做数据处理工作其中又有80%是做数据的清洗，所以选择好并学习好相关的数据分析的工具是重中之重特别是excel一定得认真学习，重点对待。</p>
<h2 id="日常积累"><a class="markdownIt-Anchor" href="#日常积累"></a> 日常积累</h2>
<p>就如同前面所说，书本知识让我们能够对Excel的基本知识有一个框架性的认识，如过真的想成长为Excel领域的专家，还是需要日常不断地加深和巩固。</p>
<p>针对加深和巩固，一方面是需要多用，把已掌握知识从会用变更熟练。二是不断汲取新知识，这个可以通过多留意一些论坛或者学习平台，<strong>“三人行，必有我师”</strong>，从与人交流中，能够看到很多自己并不了解的Excel用法。</p>
<p><img src="/images/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8BExcel2.jpg" alt="img" /></p>
<p>这里，给大家推荐2个不错的论坛，以及收集的Excel全函数表。</p>
<p><a href="https://www.excelhome.net/">Excelhome</a><br />
<a href="http://www.excelpx.com/">Excel精英论坛</a><br />
<a href="https://www.ocexa.cn:10003/d/s/734967737417211928/IxagvuBhy9eusNurwcIeusd2ypJ4xiNw-GSBgj1whMwo_">Excel函数表</a></p>
]]></content>
      <categories>
        <category>数据分析</category>
        <category>Excel</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>Excel</tag>
        <tag>数据可视化</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习基础理解</title>
    <url>/2023/02/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h2 id="数据挖掘是什么"><a class="markdownIt-Anchor" href="#数据挖掘是什么"></a> 数据挖掘是什么</h2>
<p>数据挖掘也叫机器学习，是由人工智能之父<strong>艾伦.图灵</strong>提出，其最大的成就就是图灵测试。简单理解为就是一个人和一个机器跟你去聊天，你不知道对方是人还是机器，如果经过聊天后，你分辨不出谁是人谁是机器则说明这个机器通过了图灵测试。</p>
<p><strong>机器学习</strong>是实现<strong>人工智能</strong>的一种技术手段，官方给出的人工智能诠释为：“机器学习就是从【数据】中自动分析获得【规律（模型）】，并利用规律对未知数据进行【预测】”。在通俗点讲就是“机器学习”开始是一位普通的厨师，通过不断的锻炼和菜谱（算法模型），将样本数据（食材）变为一道道美食，最终成为一位米其林大厨。</p>
<h2 id="数据挖掘基础"><a class="markdownIt-Anchor" href="#数据挖掘基础"></a> 数据挖掘基础</h2>
<ul>
<li>需要明确的几点：<br />
1.机器学习最终进行预测出来的结果其实都是通过相关的算法计算出来的结果！所以说在机器学习中算法是核心，数据是计算的基础。<br />
2.找准定位：大部分复杂模型的算法设计都是算法工程师（博士，硕士）在做，而我们只需要：
<ul>
<li>学会分析问题，使用机器学习相关算法完成对应的需求</li>
<li>掌握算法的基本思想，学会对不同问题选择对应的算法去解决</li>
<li>学会利用框架和库解决问题</li>
</ul>
</li>
</ul>
<h3 id="数据挖掘算法分类"><a class="markdownIt-Anchor" href="#数据挖掘算法分类"></a> 数据挖掘算法分类</h3>
<ul>
<li>分类和回归问题
<ul>
<li>分类算法基于的是【标签数据】为【离散型】数据<br />
回归算法基于的是【标签数据】为【连续型】数据</li>
<li>结论：在社会中产生的数据必然是离散型或者是连续型的数据，那么企业针对数据所产生的需求也无非是分类问题或者回归问题。</li>
</ul>
</li>
<li>分类问题应用：
<ul>
<li>人脸识别图像处理</li>
<li>文本分类</li>
<li>银行分类客户贷款风险</li>
</ul>
</li>
<li>回归问题应用：
<ul>
<li>股票</li>
<li>房价预测</li>
</ul>
</li>
</ul>
<h3 id="数据挖掘开发流程"><a class="markdownIt-Anchor" href="#数据挖掘开发流程"></a> 数据挖掘开发流程</h3>
<ul>
<li>1.数据采集
<ul>
<li>公司内部产生的数据</li>
<li>和其他公司合作获取的数据</li>
<li>购买的数据</li>
</ul>
</li>
<li>2.分析数据所对应要解决需求或者问题是什么？根据目标数据推断问题属于回归还是分类！</li>
<li>3.数据的基本处理
<ul>
<li>数据清洗</li>
<li>合并</li>
<li>级联等</li>
</ul>
</li>
<li>4.特征工程：对特征进行处理
<ul>
<li>特征抽取</li>
<li>特征预处理</li>
<li>降维等</li>
</ul>
</li>
<li>5.选择合适的模型，然后对其进行训练</li>
<li>6.模型的评估</li>
<li>7.上线使用</li>
</ul>
<h2 id="数据挖掘中的数据类型"><a class="markdownIt-Anchor" href="#数据挖掘中的数据类型"></a> 数据挖掘中的数据类型</h2>
<ul>
<li>机器学习中的数据类型分为：<br />
1.离散型数据：
<ul>
<li>取值范围是有限个值或者一个数列构成的，表示分类情况，如：企业数量 产品数量等</li>
<li>离散变量则是通过计数方式取得的，即是对所要统计的对象进行计数，增长量非固定的，如：一个地区的企业数目可以是今年只有一家，而第二年开了十家；一个企业的职工人数今年只有10人，第二年一次招聘了20人等。<br />
2.连续型数据：</li>
<li>连续变量是一直叠加上去的，增长量可以划分为固定的单位，即：1,2,3…… 例如：一个人的身高，他首先长到1.51，然后才能长到1.52，1.53……。</li>
<li>取值范围是一个区间，它可以在该区间中连续取值，即连续型变量可以取到区间中的任意值，并且有度量单位。例如：身高、年龄、体重、金额<br />
注意：</li>
<li>连续型数据的增长是有规律的,离散型数据的增长是没有规律的。</li>
<li>连续性数据是区间可分的，而离散型数据是区间不可分的。</li>
</ul>
</li>
</ul>
<h3 id="数据挖掘数据集划分"><a class="markdownIt-Anchor" href="#数据挖掘数据集划分"></a> 数据挖掘数据集划分</h3>
<p>是从数据中自动分析获得规律，并利用规律对未知数据进行预测。换句话说，我们的模型一定是要经过样本数据对其进行训练，才可以对未知数据进行预测的。<br />
问：我们得到数据后，是否将数据全部用来训练模型呢？<br />
当然不是的啦！因为我们如果模型（数据的规律）都是从数据中得来的，那么该模型的性能评估如何进行呢？还是基于对原先的数据进行预测吗？可想不是的，如果模型对原先的数据进行预测，由于模型（数据的规律）本来就是从该数据中获取的，所以预测的精度几乎会是百分之百。所以想要评估模型的好坏，需要使用一组新数据对模型进行评估。<br />
因此我们需要将原先的样本数据拆分成两部分：<br />
训练集：训练模型<br />
测试集：评估模型<br />
不同类型的模型对应的评估方式是不一样的</p>
<ul>
<li>数据集划分的API<br />
from sklearn.model_selection import train_test_split<br />
train_test_split(x,y,test_size,random_state)参数介绍：<br />
x：特征<br />
y：目标<br />
test_size：测试集的比例<br />
random_state：打乱的随机种子<br />
返回值：训练特征，测试特征，训练目标，测试目标</li>
</ul>
<h2 id="特征工程"><a class="markdownIt-Anchor" href="#特征工程"></a> 特征工程</h2>
<ul>
<li>
<p>为什么需要特征工程<br />
样本数据中的特征有可能会存在缺失值，重复值，异常值等等，那么我们是需要对特征中的相关的噪点数据进行处理的，那么处理的目的就是为了营造出一个更纯净的样本集（数据集越纯净则越便于让模型总结出数据集中潜在的规律），让模型基于这组数据可以有更好的预测能力。当然特征工程不是单单只是处理上述操作！</p>
</li>
<li>
<p>什么是特征工程<br />
特征工程是将原始数据转换为更好的能代表模型能够处理数据的潜在问题对应特征的过程，从而提高对未知数据预测的准确性。所以特征工程就是对特征的相关处理！<br />
比如AlphaGo学习的数据中既有棋谱，又有食谱还有歌词，那么一些干扰的数据绝对会影响AlphaGo的学习。</p>
</li>
<li>
<p>特征工程的意义<br />
直接影响模型预测的结果</p>
</li>
<li>
<p>如何实现特征工程<br />
工具：sk-learn</p>
</li>
<li>
<p>sklean介绍</p>
<ul>
<li>是python语言中的机器学习工具，包含了很多知名的机器学习算法的实现，其文档完善，容易上手。<br />
功能：<br />
分类模型<br />
回归模型<br />
聚类模型<br />
特征工程</li>
</ul>
</li>
</ul>
<h3 id="特征抽取"><a class="markdownIt-Anchor" href="#特征抽取"></a> 特征抽取</h3>
<p>目的：<br />
我们所采集到样本中的特征数据往往很多时候为字符串或者其他类型的数据，我们知道电脑只可以识别二进制数值型的数据，如果把字符串给电脑，电脑是看不懂的。机器学习学习的数据如果不是数值型的数据，它是识别不了的。</p>
<p>字符串类型的数据我们也可以成为分类变量</p>
<ul>
<li>
<p>无序分类变量</p>
<ul>
<li>说明事物类别的一个名称，如性别有男女两种，二者无大小之分，无顺序之分，还有如血型、民族等</li>
</ul>
</li>
<li>
<p>有序分类变量</p>
<ul>
<li>也是说明事物类型的一个名称，但是有次序之分，例如：满意度分为满意 一般 不满意，三者是有顺序的，you大小之分</li>
</ul>
</li>
</ul>
<p>特征值化：将非数值型的特征转换成数值型的特征</p>
<p>效果演示：<br />
将字符串转换成数字</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line">vector = CountVectorizer()</span><br><span class="line">res = vector.fit_transform([<span class="string">&#x27;lift is short,i love python&#x27;</span>,<span class="string">&#x27;lift is too long,i hate python&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(res.toarray())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>输出：[[0 1 1 0 1 1 1 0]<br />
[1 1 1 1 0 1 0 1]]</p>
<p>演示后得出：<br />
特征抽取对文本等数据进行特征值化。特征值化是为了让机器更好的理解数据。</p>
<h4 id="字典特征抽取onehot编码"><a class="markdownIt-Anchor" href="#字典特征抽取onehot编码"></a> 字典特征抽取——OneHot编码</h4>
<p><img src="/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%90%86%E8%A7%A31.png" alt="img" /></p>
<ul>
<li>为什么需要onehot编码呢？
<ul>
<li>特征抽取主要目的就是对非数值型的数据进行特征值化！如果现在需要对下图中的human和alien进行手动特征值化Alien为4，human<br />
<img src="/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%90%86%E8%A7%A32.png" alt="img" /></li>
</ul>
</li>
<li>对其进行One-Hot编码后：<br />
<img src="/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%90%86%E8%A7%A33.png" alt="img" /></li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#基于pandas实现one-hot编码</span></span><br><span class="line"><span class="comment">#    pd.get_dummies(df[&#x27;col&#x27;])</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>总结：</p>
<ul>
<li>理想情况下，无序分类变量的特征使用one-hot编码进行特征值化，有序分类变量的特征用map映射。</li>
</ul>
<h4 id="文本特征抽取"><a class="markdownIt-Anchor" href="#文本特征抽取"></a> 文本特征抽取</h4>
<ul>
<li>作用：对文本数据进行特征值化</li>
<li>API:from sklearn.feature_extraction.text import CountVectorizer</li>
<li>fit_transform(X):X为文本或者包含文本字符串的可迭代对象，返回sparse矩阵</li>
<li>inverse_transform(X)：X为array数组或者sparse矩阵，返回转换之前的格式数据</li>
<li>get_feature_names()</li>
<li>toarray()：将sparse矩阵换成数组</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line">alist = [</span><br><span class="line"></span><br><span class="line">         <span class="string">&#x27;left is is short,i love python&#x27;</span>,</span><br><span class="line"></span><br><span class="line">         <span class="string">&#x27;left is too long,i hate python&#x27;</span></span><br><span class="line"></span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">tool = CountVectorizer()</span><br><span class="line"></span><br><span class="line">ret = tool.fit_transform(alist)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(tool.get_feature_names())</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ret.toarray())</span><br><span class="line"></span><br><span class="line">[<span class="string">&#x27;hate&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;left&#x27;</span>, <span class="string">&#x27;long&#x27;</span>, <span class="string">&#x27;love&#x27;</span>, <span class="string">&#x27;python&#x27;</span>, <span class="string">&#x27;short&#x27;</span>, <span class="string">&#x27;too&#x27;</span>]</span><br><span class="line">[[<span class="number">0</span> <span class="number">2</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span>]</span><br><span class="line"> [<span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">1</span>]]</span><br></pre></td></tr></table></figure>
<p>上述文本抽取一般是给英文文章使用的，如果是中文文章，就要使用到“jieba分词”插件</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#jieba分词安装</span></span><br><span class="line">pip install jieba</span><br><span class="line"></span><br><span class="line"><span class="comment">#jieba分词的基本使用</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">s = <span class="string">&#x27;分词作用到文本特征抽取的综合使用&#x27;</span></span><br><span class="line">ret = <span class="built_in">list</span>(jieba.cut(s))</span><br><span class="line"><span class="built_in">print</span>(ret)</span><br><span class="line"></span><br><span class="line"><span class="comment">#分词作用到文本特征抽取的综合使用</span></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line">alist = [</span><br><span class="line">         <span class="string">&#x27;对有标点符号的中文文本进行特征抽取&#x27;</span>,</span><br><span class="line">         <span class="string">&#x27;因为在自然语言处理中，我们是需要将一段中文文本中相关的词语&#x27;</span></span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">jieba_alist = []</span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> alist:</span><br><span class="line">    ret = <span class="built_in">list</span>(jieba.cut(item))</span><br><span class="line">    s_ret = <span class="string">&#x27; &#x27;</span>.join(ret)<span class="comment">#ret==&gt;[你好，我也好]  &#x27; &#x27;.join(list)==&gt;&quot;你好 我也好&quot;</span></span><br><span class="line">    jieba_alist.append(s_ret)</span><br><span class="line">    </span><br><span class="line">tool = CountVectorizer()</span><br><span class="line">ret = tool.fit_transform(jieba_alist)</span><br><span class="line"><span class="built_in">print</span>(tool.get_feature_names())</span><br><span class="line"><span class="built_in">print</span>(ret.toarray())</span><br></pre></td></tr></table></figure>
<h3 id="特征的预处理"><a class="markdownIt-Anchor" href="#特征的预处理"></a> 特征的预处理</h3>
<p>对数值性数据一般进行<strong>无量纲化</strong>处理</p>
<ul>
<li>
<p>无量纲化：</p>
<ul>
<li>在机器学习算法实践中，我们往往有着将不同规格的数据转换到同一规格，或不同分布的数据转换到某个特定分布的需求这种需求统称为将数据“无量纲化”。</li>
<li>譬如梯度和矩阵为核心的算法中，譬如逻辑回归，支持向量机，神经 网络，无量纲化可以加快求解速度;</li>
<li>而在距离类模型，譬如K近邻，K-Means聚类中，无量纲化可以帮我们提升模型精度，避免某一个取值范围特别大的特征对距离计算造成影响。</li>
<li>一个特例是决策树和树的集成算法们，对决策 树我们不需要无量纲化，决策树可以把任意数据都处理得很好。<br />
那么预处理就是用来实现无量纲化的方式。<br />
含义：特征抽取后我们就可以获取对应的数值型的样本数据啦，然后就可以进行数据处理了。<br />
概念：通过特定的统计方法（数学方法），将数据转换成算法要求的数据<br />
方式：
<ul>
<li>归一化</li>
<li>标准化</li>
</ul>
</li>
</ul>
</li>
<li>
<p>归一化的实现：</p>
<ul>
<li>API:from sklearn.preprocessing import MinMaxScaler</li>
<li>参数：feature_range表示缩放范围，通常使用(0,1)</li>
<li>作用：使得某一个特征对最终结果不会造成很大的影响</li>
<li>问题：如果数据中存在的异常值比较多，会对结果造成什么样的影响？
<ul>
<li>结合着归一化计算的公式可知，异常值对原始特征中的最大值和最小值的影响很大，因此也会影响对归一化之后的值。这个也是归一化的一个弊端，无法很好的处理异常值。</li>
</ul>
</li>
<li>归一化总结：
<ul>
<li>在特定场景下最大值和最小值是变化的，另外最大最小值很容易受到异常值的影响，所以这种归一化的方式具有一定的局限性。因此引出了一种更好的方式叫做：标准化！！！</li>
</ul>
</li>
</ul>
</li>
<li>
<p>标准化的处理</p>
<ul>
<li>当数据按均值中心化后，再按标准差缩放，数据就会服从为均值为0，方差为1的正态分布(即标准正态分 布)，而这个过程，就叫做数据标准化(Standardization，又称Z-score normalization)。</li>
<li>API
<ul>
<li>处理后，每列所有的数据都聚集在均值为0，标准差为1范围附近</li>
<li>标准化API:from sklearn.preprocessing import StandardScaler
<ul>
<li>fit_transform(X):对X进行标准化</li>
<li>mean_：均值</li>
<li>var_:方差</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>归一化和标准化总结：</p>
<ul>
<li>对于归一化来说，如果出现了异常值则会响应特征的最大最小值，那么最终结果会受到比较大影响</li>
<li>对于标准化来说，如果出现异常点，由于具有一定的数据量，少量的异常点对于平均值的影响并不大，从而标准差改变比较少。</li>
</ul>
</li>
<li>
<p>StandardScaler和MinMaxScaler选哪个?</p>
<ul>
<li>看情况。大多数机器学习算法中，会选择StandardScaler来进行特征缩放，因为MinMaxScaler对异常值非常敏感。在PCA，聚类，逻辑回归，支持向量机，神经网络这些算法中，StandardScaler往往是最好的选择。 MinMaxScaler在不涉及距离度量、梯度、协方差计算以及数据需要被压缩到特定区间时使用广泛，比如数字图像处理中量化像素强度时，都会使用MinMaxScaler将数据压缩于[0,1]区间之中。</li>
<li>建议先试试看StandardScaler，效果不好换MinMaxScaler。</li>
</ul>
</li>
</ul>
<h4 id="特征选择"><a class="markdownIt-Anchor" href="#特征选择"></a> 特征选择</h4>
<p>从特征中选择出有意义对模型有帮助的特征作为最终的机器学习输入的数据！</p>
<ul>
<li>
<p>切记：</p>
<ul>
<li>在做特征选择之前，有三件非常重要的事:跟数据提供者联系，跟数据提供者沟通，跟数据提供者开会。</li>
<li>一定要抓住给你提供数据的人，尤其是理解业务和数据含义的人，跟他们聊一段时间。技术能够让模型起飞，前提是你和业务人员一样理解数据。所以特征选择的第一步，其实是根据我们的目标，用业务常识来选择特征。</li>
</ul>
</li>
<li>
<p>特征选择的原因：</p>
<ul>
<li>冗余：部分特征的相关度高，容易消耗计算机的性能
<ul>
<li>在房价预测中，有高度和楼层这两个特征</li>
</ul>
</li>
<li>噪点：部分特征对预测结果有偏执影响
<ul>
<li>在房价预测中，其中有户主血型这个特征</li>
</ul>
</li>
</ul>
</li>
<li>
<p>特征选择的实现：</p>
<ul>
<li>人为对不相关的特征进行主观舍弃</li>
<li>当然了，在真正的数据应用领域，比如金融，医疗，电商，我们的数据特征非常多，这样明显，那如果遇见极端情况，我们无法依赖对业务的理解来选择特征，该怎么办呢?
<ul>
<li>在已有特征和对应预测结果的基础上，使用相关的工具过滤掉一些无用或权重较低的特征
<ul>
<li>工具：
<ul>
<li>Filter（过滤式）【主要讲解】</li>
<li>PCA降维</li>
<li>相关性分析</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Filter过滤式（方差过滤）：</p>
<ul>
<li>原理：这是通过特征本身的方差来筛选特征的类。比如一个特征本身的方差很小，就表示样本在这个特征上基本没有差异，可能特征中的大多数值都一样，甚至整个特征的取值都相同，那这个特征对于样本区分没有什么作用。所以无论接下来的特征工程要做什么，都要优先消除方差为0或者方差极低的特征。
<ul>
<li>比如：朝阳区的房价预测，其中样本有一列特征为温度，则要知道朝阳区包含在样本中的房子对应的气象温度几乎一致或者大同小异，则温度特征则对房价的区分是无意义的。</li>
</ul>
</li>
<li>API:from sklearn.feature_selection import VarianceThreshold</li>
<li>VarianceThreshold(threshold=x)threshold方差的值，删除所有方差低于x的特征，默认值为0表示保留所有方差为非0的特征</li>
<li>fit_transform(X)#:X为特征</li>
</ul>
</li>
<li>
<p>PCA降维（主成分分析）：是一种分析，简化数据集的技术，也是【矩阵分解算法】的核心算法</p>
<ul>
<li>降维的维度值的就是特征的种类。</li>
<li>思想：如何最好的对一个立体的物体用二维表示<br />
<img src="/images/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E7%90%86%E8%A7%A34.png" alt="img" /></li>
<li>当然，第四张二维图片可以比较好的标识一个立体三维的水壶。但是也要清楚，用一个低纬度去表示高纬度的物体时，一定会造成一些信息的差异。可以让低纬度也可以能正确的表示高纬度的事物，或者信息差异最小。</li>
<li>目的：特征数量达到上百，上千的时候，考虑数据的优化。使数据维度压缩，尽可能降低源数据的维度（复杂度），损失少量信息。</li>
<li>作用：可以削减回归分析或者聚类分析中特征的数量</li>
<li>PCA语法
<ul>
<li>from sklearn.decomposition import PCA</li>
<li>pca = PCA(n_components=None)
<ul>
<li>n_components可以为小数（保留特征的百分比），整数（减少到的特征数量）</li>
</ul>
</li>
<li>pca.fit_transform(X)</li>
<li>相关系数进行特征选择</li>
<li>希望样本的特征之间相关性越低越好</li>
<li>pandas中有个一方法corr可以计算df每一列的相关系数</li>
</ul>
</li>
</ul>
</li>
<li>
<p>相关系数：（不重要）</p>
<ul>
<li>作用：用来衡量两组数据之间的相关性</li>
<li>相关系数的取值范围是：1，-1</li>
<li>相关系数越接近1：说明两组数据之间越呈现正相关，否则呈现负相关。</li>
<li>在相关系数实现的特征选择中，我们只考虑特征之间的相关性不具体考虑正负相关</li>
<li>规律：相关系数大于0.6就表示两组数据之间呈现高相关性</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>数据分析</category>
        <category>数据挖掘</category>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数据挖掘</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>线性回归及回归算法</title>
    <url>/2023/04/18/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%8F%8A%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>咳咳。之前因为有考试及生活中的琐事要处理，所以隔了很久才发布了这篇博客</p>
<h1 id="回归算法的应用"><a class="markdownIt-Anchor" href="#回归算法的应用"></a> 回归算法的应用</h1>
<ul>
<li>对于回归问题和如何使用线性回归算法做出最基础的判断
<ul>
<li>回归问题一般目标值是连续性的值，而分类问题的目标值是离散型的值。</li>
</ul>
</li>
<li>回归处理能做的预测
<ul>
<li>预测房价</li>
<li>销售额的预测</li>
<li>设定贷款额度</li>
<li>总结：可以根据事物的相关特征预测出对应的结果值，重点就是预测的能力</li>
</ul>
</li>
<li>线性回归在生活中的映射（现实生活中就有线性回归）：生活案例【预测学生的期末成绩】：
<ul>
<li>期末成绩的制定：0.7*考试成绩+0.3平时成绩，则该例子中，特征值为考试成绩和平时成绩，目标值为总成绩。从此案例中大概可以感受到
<ul>
<li>回归算法预测出来的结果其实就是经过相关的算法计算出来的结果值！</li>
<li>每一个特征需要有一个权重的占比，这个权重的占比明确后，则就可以得到最终的计算结果，也就是获取了最终预测的结果了。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>问题：假如现在有一套房子，面积为76.8平米，那么这套房子应该卖多少钱呢？也就是如何预测该套房子的价钱呢？<br />
下图中散点的分布情况就是面积和价钱这两个值之间的关系，那么如果该关系可以用一个走势的直线来表示的话，那么是不是就可以通过这条走势的直线预测出新房子的价格呢？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#现在有一组售房的数据</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas</span><br><span class="line"><span class="keyword">from</span> pandas <span class="keyword">import</span> DataFrame</span><br><span class="line"><span class="keyword">import</span> matplotlib.pylab <span class="keyword">as</span> plt</span><br><span class="line">dic = &#123;</span><br><span class="line">    <span class="string">&#x27;面积&#x27;</span>:[<span class="number">55</span>,<span class="number">76</span>,<span class="number">80</span>,<span class="number">100</span>,<span class="number">120</span>,<span class="number">150</span>],</span><br><span class="line">    <span class="string">&#x27;售价&#x27;</span>:[<span class="number">110</span>,<span class="number">152</span>,<span class="number">160</span>,<span class="number">200</span>,<span class="number">240</span>,<span class="number">300</span>]</span><br><span class="line">&#125;</span><br><span class="line">df = DataFrame(data=dic)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> mpl</span><br><span class="line">mpl.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;FangSong&#x27;</span>] <span class="comment"># 指定默认字体</span></span><br><span class="line">mpl.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span> <span class="comment"># 解决保存图像是负号&#x27;-&#x27;显示为方块的问题</span></span><br><span class="line"></span><br><span class="line">plt.scatter(df[<span class="string">&#x27;面积&#x27;</span>],df[<span class="string">&#x27;售价&#x27;</span>])</span><br><span class="line">plt.xlabel(<span class="string">&#x27;面积&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;售价&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;面积和价钱的分布图&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%921.png" alt="img" /><br />
<img src="/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%922.png" alt="img" /></p>
<ul>
<li>散点的趋势：
<ul>
<li>在上图中使用了一条直线来表示了房子的价格和面子对应的分布趋势，那么该趋势找到后，就可以基于该趋势根据新房子的面积预测出新房子的价格。</li>
</ul>
</li>
<li>线性回归的作用：
<ul>
<li>就是找出特征和目标之间存在的某种趋势！！！在二维平面中，该种趋势可以用一条线段来表示。</li>
</ul>
</li>
<li>该趋势使用什么表示呢？—》线性方程：
<ul>
<li>在数学中，线性方程y = wx就可以表示一条唯一的直线。那么在上述售房数据中，面积和价格之间的关系（二倍的关系）其实就可以映射成
<ul>
<li>价格 = 2 * 面积 ==》y=2x，这个方程就是价格和面积的趋势！也就是说根据该方程就可以进行新房子价格的预测</li>
</ul>
</li>
<li>标准的线性方程式为：y = wx + b,w为斜率，b为截距。是否带上b，得具体情况具体分析。y=wx,如果x为0，则y必定为0，那就意味着趋势对应的直线必过坐标系的原点（0，0），如果带上b值，则直线不过原点。如果上有图的趋势直线过原点的话，趋势就会不准。加b的目的是为了使得趋势对应的直线更加具有通用性！！！
<ul>
<li>如果目标值有可能为0的话，就带上b，否则不带b。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><img src="/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%923.png" alt="img" /></p>
<p>在预测中，肯定也会出现 一种情况，误差</p>
<ul>
<li>那我们如何处理误差呢？在处理误差之前，我们必须先要知道一个回归算法的特性：
<ul>
<li>回归算法是一个迭代算法。所谓的迭代就好比是系统版本的迭代，迭代后的系统要比迭代前的系统更好。
<ul>
<li>当开始训练线性回归模型的时候，是逐步的将样本数据带入模型对其进行训练的。</li>
<li>训练开始时先用部分的样本数据训练模型生成一组w和b，对应的直线和数据对应散点的误差比较大，通过不断的带入样本数据训练模型会逐步的迭代不好（误差较大）的w和b从而使得w和b的值更加的精准。</li>
</ul>
</li>
<li>官方解释：迭代是重复反馈过程的活动，其目的通常是为了逼近所需目标或结果。每一次对过程的重复称为一次“迭代”，而每一次迭代得到的结果会作为下一次迭代的初始值。</li>
<li>API
<ul>
<li>最小二乘（正规方程）：</li>
</ul>
  <figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LinearRegression</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<p><img src="/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%924.png" alt="img" /></p>
<h1 id="回归模型的评价指标"><a class="markdownIt-Anchor" href="#回归模型的评价指标"></a> 回归模型的评价指标</h1>
<ul>
<li>回归类算法的模型评估一直都是回归算法中的一个难点，回归类与分类型算法的模型评估其实是相似的法则— —找真实标签和预测值的差异。只不过在分类型算法中，这个差异只有一种角度来评判，那就是是否预测到了正确的分类，而在我们的回归类算法中，我们有两种不同的角度来看待回归的效果:
<ul>
<li>第一，我们是否预测到了正确或者接近正确的数值（因为误差的存在）。</li>
<li>第二，我们是否拟合到了足够的信息。（是否模型预测的结果线性和样本真实的结果的线性更加吻合）
<ul>
<li>这两种角度，分别对应着不同的模型评估指标。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="是否预测到了正确的数值"><a class="markdownIt-Anchor" href="#是否预测到了正确的数值"></a> 是否预测到了正确的数值</h2>
<ul>
<li>回忆一下我们的RSS残差平方和，它的本质是我们的预测值与真实值之间的差异，也就是从一种角度来评估我们回归的效力，所以RSS既是我们的损失函数，也是我们回归类模型的模型评估指标之一。但是，RSS有着致命的缺点: 它是一个无界的和，可以无限地大或者无限的小。我们只知道，我们想要求解最小的RSS，从RSS的公式来看，它不能为负，所以 RSS越接近0越好，但我们没有一个概念，究竟多小才算好，多接近0才算好?为了应对这种状况，sklearn中使用RSS 的变体，均方误差MSE(mean squared error)来衡量我们的预测值和真实值的差异:</li>
<li>均方误差，本质是在RSS的基础上除以了样本总量，得到了每个样本量上的平均误差。有了平均误差，我们就可以将平均误差和我们的标签的取值范围（最大值和最小值）在一起比较，以此获得一个较为可靠的评估依据。（查看这个错误有多严重）。
<ul>
<li>因为标签的最大值和最小值可以表示标签的一个分部情况，那么将其最大值和最小值和平均误差比较就可以大概看出在每个样本上的误差或者错误有多严重。</li>
</ul>
</li>
</ul>
<h2 id="是否拟合了足够的信息"><a class="markdownIt-Anchor" href="#是否拟合了足够的信息"></a> 是否拟合了足够的信息</h2>
<ul>
<li>对于回归类算法而言，只探索数据预测是否准确是不足够的。除了数据本身的数值大小之外，我们还希望我们的模型能够捕捉到数据的”规律“，比如数据的分布规律（抛物线），单调性等等。而是否捕获到这些信息是无法使用MSE来衡量的。<br />
<img src="/images/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%925.png" alt="img" /></li>
<li>来看这张图，其中红色线是我们的真实标签，而蓝色线是我们模型预测的值。这是一种比较极端，但的确可能发生的情况。这张图像上，前半部分的拟合非常成功，看上去我们的真实标签和我们的预测结果几乎重合，但后半部分的拟合 却非常糟糕，模型向着与真实标签完全相反的方向去了。对于这样的一个拟合模型，如果我们使用MSE来对它进行判 断，它的MSE会很小，因为大部分样本其实都被完美拟合了，少数样本的真实值和预测值的巨大差异在被均分到每个 样本上之后，MSE就会很小。但这样的拟合结果必然不是一个好结果，因为一旦我的新样本是处于拟合曲线的后半段的，我的预测结果必然会有巨大的偏差，而这不是我们希望看到的。所以，我们希望找到新的指标，除了判断预测的 数值是否正确之外，还能够判断我们的模型是否拟合了足够多的，数值之外的信息。</li>
</ul>
]]></content>
      <categories>
        <category>数据分析</category>
        <category>数据挖掘</category>
        <category>机器学习</category>
        <category>回归算法</category>
      </categories>
      <tags>
        <tag>数据分析</tag>
        <tag>数据挖掘</tag>
        <tag>机器学习</tag>
        <tag>回归算法</tag>
      </tags>
  </entry>
</search>
